{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ numpy 1.15.4\n",
    "+ pandas 0.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[230.1,  37.8,  69.2],\n",
       "       [ 44.5,  39.3,  45.1],\n",
       "       [ 17.2,  45.9,  69.3],\n",
       "       [151.5,  41.3,  58.5],\n",
       "       [180.8,  10.8,  58.4]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = adver_data[['TV','Radio','Newspaper']].values\n",
    "y = adver_data[['Sales']].values\n",
    "X[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.96985227  0.98152247  1.77894547]\n",
      " [-1.19737623  1.08280781  0.66957876]\n",
      " [-1.51615499  1.52846331  1.78354865]\n",
      " [ 0.05204968  1.21785493  1.28640506]\n",
      " [ 0.3941822  -0.84161366  1.28180188]] \n",
      " [147.0425  23.264   30.554 ]\n"
     ]
    }
   ],
   "source": [
    "means = np.mean(X, axis=0) \n",
    "stds = np.std(X, axis=0)\n",
    "X1 = (X - means) / stds\n",
    "print(X1[:5, :], '\\n', means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ones = np.ones(X1.shape[0])\n",
    "X1 = np.hstack((ones.reshape((200,1)), X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.96985227  0.98152247  1.77894547]\n",
      " [ 1.         -1.19737623  1.08280781  0.66957876]\n",
      " [ 1.         -1.51615499  1.52846331  1.78354865]\n",
      " [ 1.          0.05204968  1.21785493  1.28640506]\n",
      " [ 1.          0.3941822  -0.84161366  1.28180188]] (200, 1)\n"
     ]
    }
   ],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return np.sum((y - y_pred)**2)/len(y)\n",
    "print(X1[:5,:], y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymean = np.median(y, axis=0) \n",
    "y_pred = np.full((200,1),ymean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.1],\n",
       "       [10.4],\n",
       "       [ 9.3],\n",
       "       [18.5],\n",
       "       [12.9]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'1 задание'.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.34575"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1 = mserror(y,y_pred)\n",
    "answer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(round(answer1, 3))\n",
    "with open('task1.txt', 'w') as file:\n",
    "    file.write(str(round(answer1, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.linalg.pinv(X)@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "means1 = np.hstack((means, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([147.0425,  23.264 ,  30.554 ,   1.    ])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147.0425  23.264   30.554 ] \n",
      " [[14.0225    ]\n",
      " [ 3.91925365]\n",
      " [ 2.79206274]\n",
      " [-0.02253861]]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X1, y)\n",
    "print(means, '\\n', norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Полученный результат, округленный до 3 знаков после запятой, является ответом на *'2 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.023\n"
     ]
    }
   ],
   "source": [
    "answer2 = [1,0,0,0]@norm_eq_weights\n",
    "print(round(answer2[0], 3))\n",
    "with open('task2.txt', 'w') as file:\n",
    "    file.write(str(round(answer2[0], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return X@w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения?\n",
    "Полученный результат, округленный до 3 знаков после запятой, является ответом на *'3 задание'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y,linear_prediction(X1,norm_eq_weights))\n",
    "print(round(answer3, 3))\n",
    "with open('task3.txt', 'w') as file:\n",
    "    file.write(str(round(answer3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.96985227 0.98152247 1.77894547] [44.5 39.3 45.1]\n"
     ]
    }
   ],
   "source": [
    "print(X1[0,:], X[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    grad0 = 2 * (np.sum(X[train_ind,:]@w) - y[train_ind])*X[train_ind,0] / len(y)\n",
    "    grad1 = grad0*X[train_ind,1]\n",
    "    grad2 = grad0*X[train_ind,2]\n",
    "    grad3 = grad0*X[train_ind,3]\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- min_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = np.array([])\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(len(X))\n",
    "        \n",
    "        # Ваш код здесь\n",
    "        w_prev = w\n",
    "        w = stochastic_gradient_step(X, y, w, random_ind, eta)\n",
    "        weight_dist = np.linalg.norm(w - w_prev) \n",
    "        errors = np.append(errors, mserror(y,linear_prediction(X,w)))\n",
    "        iter_num += 1\n",
    "    if verbose==True:\n",
    "        print(w, '\\n', errors)\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.40190566e+01]\n",
      " [ 3.91069256e+00]\n",
      " [ 2.78209808e+00]\n",
      " [-8.10462217e-03]] [223.665389   223.63640485 223.5549101  ...   2.7844108    2.78441259\n",
      "   2.78441259]\n",
      "Wall time: 7.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_init = [[0],[0],[0],[0]]\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X1, y, w_init, eta=1e-2, max_iter=1e5,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([223.665389  , 223.63640485, 223.5549101 , ...,   2.7844108 ,\n",
       "         2.78441259,   2.78441259])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter[:])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40190566e+01],\n",
       "       [ 3.91069256e+00],\n",
       "       [ 2.78209808e+00],\n",
       "       [-8.10462217e-03]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.784412588406704"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'4 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784412588406704\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(y,linear_prediction(X1,stoch_grad_desc_weights))\n",
    "print(answer4)\n",
    "with open('task4.txt', 'w') as file:\n",
    "    file.write(str(round(answer4, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
